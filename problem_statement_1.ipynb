{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "problem_statement_1",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhENqr-yswvx"
      },
      "source": [
        "**Problem statement**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPavXBzQMDly"
      },
      "source": [
        "a. We have to extract the most relevant terms from this text with relevancy score and ranking table.\n",
        "\n",
        "b. We have to find similarity scores between the most relevant terms that you are extracted. \n",
        "\n",
        "c. Implement a method to prepare a short summary of the inputted text. The summary of the text should not be more than 5 lines. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2TXpqe9s7d9"
      },
      "source": [
        "**Steps of implementation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sL68OOOTMDoQ"
      },
      "source": [
        "Step - 1 first I have created vector space model The vector space model is a model used to measure the similarity between a collection of documents . Document are represented as vectors in n-dimensional space. The process of transforming query and document into a vector is called text vectorization. One of the most frequently used text vectorizer is the TF-IDF vectorizer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwCELAxHMDsW"
      },
      "source": [
        "Step-2 Then i have created word frequency table with the help of spacy library to check the frequency distribution of different words to find the importance of different words in the given passage. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtLHUmFTMDwh"
      },
      "source": [
        "Step -3 In the last step i have given the summary of the passage in nearly 5 lines by selecting the most frequent and important lines and also given the importance of the lines in terms of frequency \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c3lIJ7ylU3v"
      },
      "source": [
        "Imported some important **libraries** and downloaded some **packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkFAhN7m-5yd",
        "outputId": "0afd01bd-2e6d-49ca-d192-e781c4db3b94"
      },
      "source": [
        "\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "# imported spacy library\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from string import punctuation"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm6B_dPWmObF"
      },
      "source": [
        "**Passage** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmf1Ts7hW2VM"
      },
      "source": [
        "paragraph = \"\"\"Junkfood - Food that do no good to our body. And there's no need of them\n",
        "in our body but still we willingly eat them because they are great in taste and easy to cook\n",
        "or ready to eat. Junk foods have no or very less nutritional value and irrespective of the way\n",
        "they are marketed, they are not healthy to consume.The only reason of their gaining popularity \n",
        "and increased trend of consumption is that they are ready to eat or easy to cook foods.\n",
        "People, of all age groups are moving towards Junkfood as it is hassle free and often ready \n",
        "to grab and eat. Cold drinks, chips, noodles, pizza, burgers, French fries etc. are few examples\n",
        "from the great variety of junk food available in the market.\n",
        " Junkfood is the most dangerous food ever but it is pleasure in eating and it gives a great taste \n",
        " in mouth examples of Junkfood are kurkure and chips.. cold rings are also source of junk food...\n",
        " they shud nt be ate in high amounts as it results fatal to our body... it cn be eated in a limited \n",
        " extend ... in research its found tht ths junk foods r very dangerous fr our health\n",
        "Junkfood is very harmful that is slowly eating away the health of the present generation.\n",
        "The term itself denotes how dangerous it is for our bodies.\n",
        "Most importantly, it tastes so good that people consume it on a daily basis.\n",
        "However, not much awareness is spread about the harmful effects of Junkfood .\n",
        "The problem is more serious than you think. Various studies show that Junkfood impacts\n",
        "our health negatively. They contain higher levels of calories, fats, and sugar. \n",
        "On the contrary, they have very low amounts of healthy nutrients and lack dietary fibers. \n",
        "Parents must discourage their children from consuming junk food because of the ill effects \n",
        "it has on oneâ€™s health.\n",
        "Junkfood is the easiest way to gain unhealthy weight. The amount of fats and sugar \n",
        "in the food makes you gain weight rapidly. However, this is not a healthy weight.\n",
        "It is more of fats and cholesterol which will have a harmful impact on your health.\n",
        "Junk food is also one of the main reasons for the increase in obesity nowadays.\n",
        "This food only looks and tastes good, other than that, it has no positive points.\n",
        "The amount of calorie your body requires to stay fit is not fulfilled by this food.\n",
        "For instance, foods like French fries, burgers, candy, and cookies, all have high amounts\n",
        "of sugar and fats. Therefore, this can result in long-term illnesses like diabetes and \n",
        "high blood pressure. This may also result in kidney failure.\"\"\"\n",
        "               "
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNC66GYHmc6J"
      },
      "source": [
        "Making object of **lemmatizer** and **tokenising** the passage "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGU8Swlud200"
      },
      "source": [
        "wordnet=WordNetLemmatizer()"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HZFhV0ld23I"
      },
      "source": [
        "sentences=nltk.sent_tokenize(paragraph)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQhHuyLQm0oy"
      },
      "source": [
        "**Cleaning of data** by lemmatizer and removing other than words in passage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cFzzNIGd25q"
      },
      "source": [
        "corpus=[]\n",
        "for i in range(len(sentences)):\n",
        "    review =re.sub('[^a-zA-z]',' ',sentences[i])\n",
        "    review =review.lower()\n",
        "    review=review.split()\n",
        "    review=[wordnet.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
        "    review=' '.join(review)\n",
        "    corpus.append(review)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlJKD6fFnTdO"
      },
      "source": [
        "Importing **TF-IDF vectorizer** from sklearn and applying transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2bjvabKd29I"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "cv=TfidfVectorizer()\n",
        "x=cv.fit_transform(corpus).toarray()"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCeikv9SoTGB"
      },
      "source": [
        "Vector space model to find **relavancy score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAIbKnjhd3Jl",
        "outputId": "1cd0f2e6-3290-432d-b45f-89b9cd4f13d6"
      },
      "source": [
        "x         "
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.32452515],\n",
              "       [0.        , 0.        , 0.        , ..., 0.21221025, 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.23397949, ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.38857455, 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guelX6aFo13-"
      },
      "source": [
        "Implementing the spacy library in order to **create frequency table** and **summary** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qgmuoRyo1qL"
      },
      "source": [
        "Importing stopwords and punctuations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvSFfbqQ342L"
      },
      "source": [
        "stopwords =list(STOP_WORDS)\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc=nlp(paragraph)\n",
        "punctuation = punctuation +'\\n'"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20YX0PY7prGM"
      },
      "source": [
        "To find the word **frequency table** by removing stopwords and punctuations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tqN0kM95DkO",
        "outputId": "2f5c8a5b-6b65-44b4-b94c-8796889b954a"
      },
      "source": [
        "word_frequencies ={}\n",
        "for word in doc:\n",
        "  if word.text.lower() not in stopwords:\n",
        "    if word.text.lower() not in punctuation:\n",
        "      if word.text not in word_frequencies.keys():\n",
        "        word_frequencies[word.text] =1 \n",
        "      else:\n",
        "        word_frequencies[word.text] +=1 \n",
        "\n",
        "word_frequencies"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n ': 4,\n",
              " '..': 1,\n",
              " '...': 3,\n",
              " 'Cold': 1,\n",
              " 'Food': 1,\n",
              " 'French': 2,\n",
              " 'Junk': 2,\n",
              " 'Junkfood': 8,\n",
              " 'Parents': 1,\n",
              " 'People': 1,\n",
              " 'age': 1,\n",
              " 'amounts': 3,\n",
              " 'ate': 1,\n",
              " 'available': 1,\n",
              " 'awareness': 1,\n",
              " 'away': 1,\n",
              " 'basis': 1,\n",
              " 'blood': 1,\n",
              " 'bodies': 1,\n",
              " 'body': 4,\n",
              " 'burgers': 2,\n",
              " 'calorie': 1,\n",
              " 'calories': 1,\n",
              " 'candy': 1,\n",
              " 'children': 1,\n",
              " 'chips': 2,\n",
              " 'cholesterol': 1,\n",
              " 'cn': 1,\n",
              " 'cold': 1,\n",
              " 'consume': 2,\n",
              " 'consuming': 1,\n",
              " 'consumption': 1,\n",
              " 'contain': 1,\n",
              " 'contrary': 1,\n",
              " 'cook': 2,\n",
              " 'cookies': 1,\n",
              " 'daily': 1,\n",
              " 'dangerous': 3,\n",
              " 'denotes': 1,\n",
              " 'diabetes': 1,\n",
              " 'dietary': 1,\n",
              " 'discourage': 1,\n",
              " 'drinks': 1,\n",
              " 'easiest': 1,\n",
              " 'easy': 2,\n",
              " 'eat': 4,\n",
              " 'eated': 1,\n",
              " 'eating': 2,\n",
              " 'effects': 2,\n",
              " 'etc': 1,\n",
              " 'examples': 2,\n",
              " 'extend': 1,\n",
              " 'failure': 1,\n",
              " 'fatal': 1,\n",
              " 'fats': 4,\n",
              " 'fibers': 1,\n",
              " 'fit': 1,\n",
              " 'food': 8,\n",
              " 'foods': 4,\n",
              " 'found': 1,\n",
              " 'fr': 1,\n",
              " 'free': 1,\n",
              " 'fries': 2,\n",
              " 'fulfilled': 1,\n",
              " 'gain': 2,\n",
              " 'gaining': 1,\n",
              " 'generation': 1,\n",
              " 'gives': 1,\n",
              " 'good': 3,\n",
              " 'grab': 1,\n",
              " 'great': 3,\n",
              " 'groups': 1,\n",
              " 'harmful': 3,\n",
              " 'hassle': 1,\n",
              " 'health': 5,\n",
              " 'healthy': 3,\n",
              " 'high': 3,\n",
              " 'higher': 1,\n",
              " 'ill': 1,\n",
              " 'illnesses': 1,\n",
              " 'impact': 1,\n",
              " 'impacts': 1,\n",
              " 'importantly': 1,\n",
              " 'increase': 1,\n",
              " 'increased': 1,\n",
              " 'instance': 1,\n",
              " 'irrespective': 1,\n",
              " 'junk': 4,\n",
              " 'kidney': 1,\n",
              " 'kurkure': 1,\n",
              " 'lack': 1,\n",
              " 'levels': 1,\n",
              " 'like': 2,\n",
              " 'limited': 1,\n",
              " 'long': 1,\n",
              " 'looks': 1,\n",
              " 'low': 1,\n",
              " 'main': 1,\n",
              " 'makes': 1,\n",
              " 'market': 1,\n",
              " 'marketed': 1,\n",
              " 'mouth': 1,\n",
              " 'moving': 1,\n",
              " 'need': 1,\n",
              " 'negatively': 1,\n",
              " 'noodles': 1,\n",
              " 'nowadays': 1,\n",
              " 'nt': 1,\n",
              " 'nutrients': 1,\n",
              " 'nutritional': 1,\n",
              " 'obesity': 1,\n",
              " 'people': 1,\n",
              " 'pizza': 1,\n",
              " 'pleasure': 1,\n",
              " 'points': 1,\n",
              " 'popularity': 1,\n",
              " 'positive': 1,\n",
              " 'present': 1,\n",
              " 'pressure': 1,\n",
              " 'problem': 1,\n",
              " 'r': 1,\n",
              " 'rapidly': 1,\n",
              " 'ready': 3,\n",
              " 'reason': 1,\n",
              " 'reasons': 1,\n",
              " 'requires': 1,\n",
              " 'research': 1,\n",
              " 'result': 2,\n",
              " 'results': 1,\n",
              " 'rings': 1,\n",
              " 'shud': 1,\n",
              " 'slowly': 1,\n",
              " 'source': 1,\n",
              " 'spread': 1,\n",
              " 'stay': 1,\n",
              " 'studies': 1,\n",
              " 'sugar': 3,\n",
              " 'taste': 2,\n",
              " 'tastes': 2,\n",
              " 'term': 2,\n",
              " 'think': 1,\n",
              " 'ths': 1,\n",
              " 'tht': 1,\n",
              " 'trend': 1,\n",
              " 'unhealthy': 1,\n",
              " 'value': 1,\n",
              " 'variety': 1,\n",
              " 'way': 2,\n",
              " 'weight': 3,\n",
              " 'willingly': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8Ti6GCoqHZc"
      },
      "source": [
        "Creating a **normalize frequency table** dividing the table frequency with maximum frequency.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YE7MYen06Pzp",
        "outputId": "1e96a568-5306-4f06-8f55-90193d19c25d"
      },
      "source": [
        "max_frequencies=max(word_frequencies.values())\n",
        "\n",
        "for word in word_frequencies.keys():\n",
        "  word_frequencies[word] =word_frequencies[word]/max_frequencies\n",
        "\n",
        "print(word_frequencies)  "
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Junkfood': 1.0, 'Food': 0.125, 'good': 0.375, 'body': 0.5, 'need': 0.125, 'willingly': 0.125, 'eat': 0.5, 'great': 0.375, 'taste': 0.25, 'easy': 0.25, 'cook': 0.25, 'ready': 0.375, 'Junk': 0.25, 'foods': 0.5, 'nutritional': 0.125, 'value': 0.125, 'irrespective': 0.125, 'way': 0.25, 'marketed': 0.125, 'healthy': 0.375, 'consume': 0.25, 'reason': 0.125, 'gaining': 0.125, 'popularity': 0.125, 'increased': 0.125, 'trend': 0.125, 'consumption': 0.125, 'People': 0.125, 'age': 0.125, 'groups': 0.125, 'moving': 0.125, 'hassle': 0.125, 'free': 0.125, 'grab': 0.125, 'Cold': 0.125, 'drinks': 0.125, 'chips': 0.25, 'noodles': 0.125, 'pizza': 0.125, 'burgers': 0.25, 'French': 0.25, 'fries': 0.25, 'etc': 0.125, 'examples': 0.25, 'variety': 0.125, 'junk': 0.5, 'food': 1.0, 'available': 0.125, 'market': 0.125, '\\n ': 0.5, 'dangerous': 0.375, 'pleasure': 0.125, 'eating': 0.25, 'gives': 0.125, 'mouth': 0.125, 'kurkure': 0.125, '..': 0.125, 'cold': 0.125, 'rings': 0.125, 'source': 0.125, '...': 0.375, 'shud': 0.125, 'nt': 0.125, 'ate': 0.125, 'high': 0.375, 'amounts': 0.375, 'results': 0.125, 'fatal': 0.125, 'cn': 0.125, 'eated': 0.125, 'limited': 0.125, 'extend': 0.125, 'research': 0.125, 'found': 0.125, 'tht': 0.125, 'ths': 0.125, 'r': 0.125, 'fr': 0.125, 'health': 0.625, 'harmful': 0.375, 'slowly': 0.125, 'away': 0.125, 'present': 0.125, 'generation': 0.125, 'term': 0.25, 'denotes': 0.125, 'bodies': 0.125, 'importantly': 0.125, 'tastes': 0.25, 'people': 0.125, 'daily': 0.125, 'basis': 0.125, 'awareness': 0.125, 'spread': 0.125, 'effects': 0.25, 'problem': 0.125, 'think': 0.125, 'studies': 0.125, 'impacts': 0.125, 'negatively': 0.125, 'contain': 0.125, 'higher': 0.125, 'levels': 0.125, 'calories': 0.125, 'fats': 0.5, 'sugar': 0.375, 'contrary': 0.125, 'low': 0.125, 'nutrients': 0.125, 'lack': 0.125, 'dietary': 0.125, 'fibers': 0.125, 'Parents': 0.125, 'discourage': 0.125, 'children': 0.125, 'consuming': 0.125, 'ill': 0.125, 'easiest': 0.125, 'gain': 0.25, 'unhealthy': 0.125, 'weight': 0.375, 'makes': 0.125, 'rapidly': 0.125, 'cholesterol': 0.125, 'impact': 0.125, 'main': 0.125, 'reasons': 0.125, 'increase': 0.125, 'obesity': 0.125, 'nowadays': 0.125, 'looks': 0.125, 'positive': 0.125, 'points': 0.125, 'calorie': 0.125, 'requires': 0.125, 'stay': 0.125, 'fit': 0.125, 'fulfilled': 0.125, 'instance': 0.125, 'like': 0.25, 'candy': 0.125, 'cookies': 0.125, 'result': 0.25, 'long': 0.125, 'illnesses': 0.125, 'diabetes': 0.125, 'blood': 0.125, 'pressure': 0.125, 'kidney': 0.125, 'failure': 0.125}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3TjXjCFL6MA"
      },
      "source": [
        "Tokenizing the sentence and implementing the **sentence frequency** which will give score of sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ_ZLBjY5Vt_",
        "outputId": "22f865e5-8ace-4ff9-9e75-8162cb70d38d"
      },
      "source": [
        "sentences_tokens =[sent for sent in doc.sents]\n",
        "sentence_scores ={}\n",
        "for sent in sentences_tokens:\n",
        "  for word in sent:\n",
        "    if word.text.lower() in word_frequencies.keys():\n",
        "      if sent not in sentence_scores.keys():\n",
        "          sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
        "      else:\n",
        "          sentence_scores[sent] += word_frequencies[word.text.lower()]\n",
        "\n",
        "sentence_scores"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{Junkfood - Food that do no good to our body.: 1.875,\n",
              " And there's no need of them\n",
              " in our body: 0.625,\n",
              " but still we willingly eat them because they are great in taste and easy to cook\n",
              " or ready to eat.: 2.625,\n",
              " Junk foods have no or very less nutritional value and irrespective of the way: 1.625,\n",
              " they are marketed, they are not healthy to consume.: 0.75,\n",
              " The only reason of their gaining popularity \n",
              " and increased trend of consumption is that they are ready to eat or easy to cook foods.: 2.625,\n",
              " People, of all age groups are moving towards Junkfood as it is hassle free and often ready \n",
              " to grab and eat.: 1.75,\n",
              " Cold drinks, chips, noodles, pizza, burgers, French fries etc.: 1.375,\n",
              " are few examples\n",
              " from the great variety of junk food available in the market.\n",
              "  : 3.0,\n",
              " Junkfood is the most dangerous food ever but it is pleasure in eating and it gives a great taste \n",
              "  in mouth examples of Junkfood are kurkure and chips..: 3.875,\n",
              " cold rings are also source of junk food...\n",
              "  : 2.75,\n",
              " they shud nt be ate in high amounts as it results fatal to our body...: 2.25,\n",
              " it cn be eated in a limited \n",
              "  extend ... in research: 1.5,\n",
              " its found tht ths junk foods: 1.375,\n",
              " r very dangerous fr our health: 1.25,\n",
              " Junkfood is very harmful that is slowly eating away the health of the present generation.: 1.75,\n",
              " The term itself denotes how dangerous it is for our bodies.: 0.875,\n",
              " Most importantly, it tastes so good that people consume it on a daily basis.: 1.375,\n",
              " However, not much awareness is spread about the harmful effects of Junkfood .: 0.875,\n",
              " The problem is more serious than you think.: 0.25,\n",
              " Various studies show that Junkfood impacts\n",
              " our health negatively.: 1.0,\n",
              " They contain higher levels of calories, fats, and sugar. : 1.375,\n",
              " On the contrary, they have very low amounts of healthy nutrients and lack dietary fibers. : 1.5,\n",
              " Parents must discourage their children from consuming junk food because of the ill effects : 2.25,\n",
              " it has on oneâ€™s health.: 0.625,\n",
              " Junkfood is the easiest way to gain unhealthy weight.: 1.125,\n",
              " The amount of fats and sugar \n",
              " in the food makes you gain weight rapidly.: 2.75,\n",
              " However, this is not a healthy weight.: 0.75,\n",
              " It is more of fats and cholesterol which will have a harmful impact on your health.: 1.75,\n",
              " Junk food is also one of the main reasons for the increase in obesity nowadays.: 2.125,\n",
              " This food only looks and tastes good, other than that, it has no positive points.: 2.0,\n",
              " The amount of calorie your body requires to stay fit is not fulfilled by this food.: 2.125,\n",
              " For instance, foods like French fries, burgers, candy, and cookies, all have high amounts\n",
              " of sugar and fats.: 3.25,\n",
              " Therefore, this can result in long-term illnesses like diabetes and \n",
              " high blood pressure.: 1.75,\n",
              " This may also result in kidney failure.: 0.5}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iapa9Rc1rSCN"
      },
      "source": [
        "Getting the **summary** of the data with the help of nlargest function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIk6CQ-s6CWb",
        "outputId": "418dc2f7-0d81-438f-8b3d-2b01537853ea"
      },
      "source": [
        "from heapq import nlargest\n",
        "\n",
        "select_lenth = int(len(sentences_tokens)*0.18)\n",
        "summary = nlargest(select_lenth,sentence_scores,key=sentence_scores.get)\n",
        "\n",
        "summary"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Junkfood is the most dangerous food ever but it is pleasure in eating and it gives a great taste \n",
              "  in mouth examples of Junkfood are kurkure and chips..,\n",
              " For instance, foods like French fries, burgers, candy, and cookies, all have high amounts\n",
              " of sugar and fats.,\n",
              " are few examples\n",
              " from the great variety of junk food available in the market.\n",
              "  ,\n",
              " cold rings are also source of junk food...\n",
              "  ,\n",
              " The amount of fats and sugar \n",
              " in the food makes you gain weight rapidly.,\n",
              " but still we willingly eat them because they are great in taste and easy to cook\n",
              " or ready to eat.]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0O_Vbghsrlrl"
      },
      "source": [
        "Conclusion - Successfully obtained the relevance ranking of the most important words in the Passage , obtained the frequency table of most impotant words and drawn out the summary of the data five lines."
      ]
    }
  ]
}